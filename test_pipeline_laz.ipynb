{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e8be998c-5e96-47f3-b006-03e6ab3274db",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7076472e-2579-4f00-b3ad-cb9c9e239256",
   "metadata": {},
   "outputs": [],
   "source": [
    "# <your imports>\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.optim import Adam\n",
    "import torch.nn as nn\n",
    "from tqdm.notebook import tqdm\n",
    "from omegaconf import OmegaConf\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import TrainingArguments, Trainer\n",
    "from transformers import BertForSequenceClassification, XLMRobertaXLConfig\n",
    "from transformers import EarlyStoppingCallback\n",
    "\n",
    "from preprocessing import Preprocessing\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# models\n",
    "from models import BertClassifier\n",
    "from transformers import BertTokenizer\n",
    "\n",
    "# ignore fucking warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0ecfef7a-1615-40cd-90cc-dcce3a9c1793",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique labels: [0 1 2]\n"
     ]
    }
   ],
   "source": [
    "datapath = 'data/data_ruSentNE_lemmatized.csv'\n",
    "df = pd.read_csv(datapath)\n",
    "mapping = {\n",
    "    -1: 0,\n",
    "    0: 1,\n",
    "    1: 2\n",
    "}\n",
    "\n",
    "df[\"label\"] = df[\"category\"].map(mapping)\n",
    "        \n",
    "print(f\"Unique labels: {np.unique(df.label)}\")\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8ff248c7-c849-4a3f-a2d7-3dec9b317341",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-cased')\n",
    "labels = {\n",
    "    -1: 0,\n",
    "    0: 1,\n",
    "    1: 2\n",
    "}\n",
    "\n",
    "class Dataset(torch.utils.data.Dataset):\n",
    "\n",
    "    def __init__(self, df, equalize=False):\n",
    "\n",
    "        self.labels = df['label'].values\n",
    "        self.texts = [tokenizer(text, \n",
    "                               padding='max_length', max_length = 512, truncation=True,\n",
    "                                return_tensors=\"pt\") for text in df['text']]\n",
    "        if equalize:\n",
    "            _, counts = np.unique(df['label'].values, return_counts=True)\n",
    "            \n",
    "    def classes(self):\n",
    "        return self.labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def get_batch_labels(self, idx):\n",
    "        # Fetch a batch of labels\n",
    "        return np.array(self.labels[idx])\n",
    "\n",
    "    def get_batch_texts(self, idx):\n",
    "        # Fetch a batch of inputs\n",
    "        return self.texts[idx]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        batch_texts = self.get_batch_texts(idx)\n",
    "        batch_y = self.get_batch_labels(idx)\n",
    "\n",
    "        return batch_texts, batch_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0f0cee4d-516f-4ce8-9dfc-3875de1623fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7585 1897\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(112)\n",
    "df_train, df_val = train_test_split(\n",
    "                df,\n",
    "                test_size=0.2,\n",
    "                random_state=42,\n",
    "                shuffle=True,\n",
    "                stratify=df[\"label\"],\n",
    "            )\n",
    "\n",
    "print(len(df_train),len(df_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e0d09bfc-6887-412b-b019-98ae5d396357",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1, 2]), array([1156, 5455,  974]))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(df_train.label, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2a9b9f83-1a62-4df2-b879-19d1f43b05d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"metric_test.txt\", 'w'):\n",
    "    pass\n",
    "\n",
    "def custom_f1(pred, labels):\n",
    "    pred = np.argmax(pred.cpu().numpy(), axis=1)\n",
    "    with open(\"metric_test.txt\", 'a') as f:\n",
    "        f.write(\" \".join(map(str, labels.cpu().numpy())))\n",
    "        f.write(\"\\n\")\n",
    "        f.write(\" \".join(map(str, pred)))\n",
    "        f.write(\"\\n\")\n",
    "        f.write(\"\\n\")\n",
    "    f1_scores = f1_score(y_true=labels.cpu().numpy(), y_pred=pred, average=None)\n",
    "    final_score = np.mean(f1_scores[1:])\n",
    "    # return {\"custom F1 score\": final_score}\n",
    "    return {\n",
    "        \"F1 for class 0\": f1_scores[0],\n",
    "        \"F1 for class 1\": f1_scores[1],\n",
    "        \"F1 for class 2\": f1_scores[2]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a1233f08-dc80-43c0-8ada-3f6af7c0b4c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in train_dl:\n",
    "#     print(i)\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "429e2475-1e38-4758-be7b-303bef821c1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a59d4a7ae4224ad78baee8a1816ba33c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67bd126bba0e477893d919cb6ee031df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/238 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 1 | Train Loss:  0.003                 \n",
      "| Val Loss:  0.017                 \n",
      "| F1 for 0 class: 0.28571428571428575                 \n",
      "| F1 for 1 class: 0.368421052631579                 \n",
      "| F1 for 2 class: 0.25                 \n",
      "| Train Accuracy:  0.021                 \n",
      "| Val Accuracy:  0.271\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d69735316eff465aaf6477a97c3ef62c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/238 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 2 | Train Loss:  0.003                 \n",
      "| Val Loss:  0.017                 \n",
      "| F1 for 0 class: 0.25806451612903225                 \n",
      "| F1 for 1 class: 0.42105263157894735                 \n",
      "| F1 for 2 class: 0.0                 \n",
      "| Train Accuracy:  0.026                 \n",
      "| Val Accuracy:  0.326\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d7ac5eae90c446bac03b60b23468231",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/238 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 3 | Train Loss:  0.003                 \n",
      "| Val Loss:  0.017                 \n",
      "| F1 for 0 class: 0.375                 \n",
      "| F1 for 1 class: 0.4                 \n",
      "| F1 for 2 class: 0.2                 \n",
      "| Train Accuracy:  0.029                 \n",
      "| Val Accuracy:  0.376\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6c1f0524fcb4a8398e65df59581282b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/238 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 4 | Train Loss:  0.003                 \n",
      "| Val Loss:  0.016                 \n",
      "| F1 for 0 class: 0.1739130434782609                 \n",
      "| F1 for 1 class: 0.627450980392157                 \n",
      "| F1 for 2 class: 0.0                 \n",
      "| Train Accuracy:  0.038                 \n",
      "| Val Accuracy:  0.467\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8b9a61bfa9340f59b35448e7d2563a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/238 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 5 | Train Loss:  0.003                 \n",
      "| Val Loss:  0.015                 \n",
      "| F1 for 0 class: 0.13333333333333333                 \n",
      "| F1 for 1 class: 0.7000000000000001                 \n",
      "| F1 for 2 class: 0.0                 \n",
      "| Train Accuracy:  0.047                 \n",
      "| Val Accuracy:  0.623\n"
     ]
    }
   ],
   "source": [
    "def train(model, train_data, val_data, learning_rate, epochs):\n",
    "    train, val = Dataset(train_data), Dataset(val_data)\n",
    "    \n",
    "    train_dataloader = torch.utils.data.DataLoader(train, batch_size=32, shuffle=True)\n",
    "    val_dataloader = torch.utils.data.DataLoader(val, batch_size=64)\n",
    "\n",
    "    use_cuda = torch.cuda.is_available()\n",
    "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = Adam(model.parameters(), lr= learning_rate)\n",
    "    if use_cuda:\n",
    "\n",
    "            model = model.cuda()\n",
    "            criterion = criterion.cuda()\n",
    "    \n",
    "    for epoch_num in tqdm(range(epochs)):\n",
    "\n",
    "            total_acc_train = 0\n",
    "            total_loss_train = 0\n",
    "            count=0\n",
    "            for train_input, train_label in tqdm(train_dataloader):\n",
    "                count+=1\n",
    "                train_label = train_label.to(device)\n",
    "                mask = train_input['attention_mask'].to(device)\n",
    "                input_id = train_input['input_ids'].squeeze(1).to(device)\n",
    "\n",
    "                output = model(input_id, mask)\n",
    "                \n",
    "                batch_loss = criterion(output, train_label.long())\n",
    "                total_loss_train += batch_loss.item()\n",
    "                \n",
    "                acc = (output.argmax(dim=1) == train_label).sum().item()\n",
    "                total_acc_train += acc\n",
    "\n",
    "                model.zero_grad()\n",
    "                batch_loss.backward()\n",
    "                optimizer.step()\n",
    "                if count >= 20:\n",
    "                    break\n",
    "            total_acc_val = 0\n",
    "            total_loss_val = 0\n",
    "\n",
    "            with torch.no_grad():\n",
    "\n",
    "                for val_input, val_label in val_dataloader:\n",
    "\n",
    "                    val_label = val_label.to(device)\n",
    "                    mask = val_input['attention_mask'].to(device)\n",
    "                    input_id = val_input['input_ids'].squeeze(1).to(device)\n",
    "\n",
    "                    output = model(input_id, mask)\n",
    "\n",
    "                    batch_loss = criterion(output, val_label.long())\n",
    "                    total_loss_val += batch_loss.item()\n",
    "                    \n",
    "                    acc = (output.argmax(dim=1) == val_label).sum().item()\n",
    "                    total_acc_val += acc\n",
    "                    \n",
    "                    metrics = custom_f1(output, val_label)\n",
    "            print(\n",
    "                f\"Epochs: {epoch_num + 1} | Train Loss: {total_loss_train / len(train_data): .3f} \\\n",
    "                \\n| Val Loss: {total_loss_val / len(val_data): .3f} \\\n",
    "                \\n| F1 for 0 class: {metrics['F1 for class 0']} \\\n",
    "                \\n| F1 for 1 class: {metrics['F1 for class 1']} \\\n",
    "                \\n| F1 for 2 class: {metrics['F1 for class 2']} \\\n",
    "                \\n| Train Accuracy: {total_acc_train / len(train_data): .3f} \\\n",
    "                \\n| Val Accuracy: {total_acc_val / len(val_data): .3f}\")\n",
    "                  \n",
    "EPOCHS = 5\n",
    "model = BertClassifier(\n",
    "    num_classes=3\n",
    ")\n",
    "LR = 1e-6\n",
    "\n",
    "train(model, df_train, df_val, LR, EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "392df6cf-bbac-43a4-a307-1d0c26bb12f9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
