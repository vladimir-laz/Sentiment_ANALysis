{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d2f43258-33cc-444e-ad3f-532c376e278b",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e3863407-6d96-42dd-b61e-cf732b329b7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# <your imports>\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.optim import Adam\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm\n",
    "from omegaconf import OmegaConf\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n",
    "from transformers import TrainingArguments, Trainer\n",
    "from transformers import BertForSequenceClassification, XLMRobertaXLConfig\n",
    "from transformers import EarlyStoppingCallback\n",
    "\n",
    "import sys\n",
    "sys.path.append('../src')\n",
    "from preprocessing import Preprocessing\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# models\n",
    "from models import BertClassifier\n",
    "\n",
    "# ignore fucking warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "203b3315-91e2-4143-a67c-729e15617057",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"metric_test.txt\", 'w'):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "115fdfdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_f1(p):\n",
    "    pred, labels = p\n",
    "    with open(\"metric_test.txt\", 'a') as f:\n",
    "        f.write(\" \".join(map(str, labels)))\n",
    "        f.write(\"\\n\")\n",
    "        for pred_i in pred:\n",
    "            f.write(\" \".join(map(str, pred_i)))\n",
    "            f.write(\"\\n\")\n",
    "    pred = np.argmax(pred, axis=1)\n",
    "\n",
    "    f1_scores = f1_score(y_true=labels, y_pred=pred, average=None)\n",
    "    final_score = np.mean(f1_scores[1:])\n",
    "    # return {\"custom F1 score\": final_score}\n",
    "    return {\n",
    "        \"F1 for class 0\": f1_scores[0],\n",
    "        \"F1 for class 1\": f1_scores[1],\n",
    "        \"F1 for class 2\": f1_scores[2]\n",
    "    }\n",
    "\n",
    "def compute_metrics(p):\n",
    "    pred, labels = p\n",
    "    # print(pred, labels)\n",
    "    # print(np.unique(labels, return_counts=True), labels.shape)\n",
    "    pred = np.argmax(pred, axis=1)\n",
    "\n",
    "    accuracy = accuracy_score(y_true=labels, y_pred=pred)\n",
    "    recall = recall_score(y_true=labels, y_pred=pred, average='weighted')\n",
    "    precision = precision_score(y_true=labels, y_pred=pred, average='weighted')\n",
    "    f1 = f1_score(y_true=labels, y_pred=pred, average='weighted')\n",
    "\n",
    "    return {\"accuracy\": accuracy, \"precision\": precision, \"recall\": recall, \"f1\": f1}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3bcbd38-0667-4f85-b469-a21c325c2c78",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Data loading/preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "753f1dfd-f326-4c7c-89f6-f6fc6a0ca4a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = Preprocessing()\n",
    "\n",
    "# result = preprocessor.get_dataloaders()\n",
    "result = preprocessor.get_datasets()\n",
    "\n",
    "train_set = result[\"train_set\"]\n",
    "val_set = result[\"val_set\"]\n",
    "# plt.hist(val_set.labels, bins=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cea22ad-5730-4238-9058-5cd58a6905c3",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Model initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "be3a22f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_name: ruSentNE\n",
      "batch_size: 64\n",
      "device: cpu:0\n",
      "dataloader_shuffle: True\n",
      "pretrained_model: bert-base-uncased\n",
      "num_classes: 3\n",
      "num_workers: 1\n",
      "lr: 1e-06\n",
      "epochs: 5\n",
      "eps: 1e-08\n",
      "optimizer: AdamW\n",
      "eval_steps: 10\n",
      "logging_steps: 10\n"
     ]
    }
   ],
   "source": [
    "conf = OmegaConf.load(\"../config.yaml\").general\n",
    "for i in conf.keys():\n",
    "    print(f'{i}: {conf[i]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "604034b9-26ff-4fff-a65b-472bc03017a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    \"cardiffnlp/twitter-roberta-base-sentiment\", \n",
    "    # 'cardiffnlp/twitter-xlm-roberta-base-sentiment',\n",
    "    num_labels=3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "0670d392-d643-4875-b210-9cebefa70dea",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# for param in model.roberta.parameters():\n",
    "#     param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "8a6305d7-241d-4505-adef-37d0343e46cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.classifier = nn.Linear(in_features=768, out_features=3, bias=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "40be5d9f-8903-4893-bae1-8572005418b6",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# help(AutoModelForSequenceClassification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "81547532",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # model = BertForSequenceClassification.from_pretrained(conf.pretrained_model,\n",
    "# #                                                       num_labels=conf.num_classes,\n",
    "# #                                                       output_attentions=False,\n",
    "# #                                                       output_hidden_states=False)\n",
    "\n",
    "# model = XLMRobertaXLModel.from_pretrained(conf.pretrained_model,\n",
    "#                                            num_labels=conf.num_classes,\n",
    "#                                            output_attentions=False,\n",
    "#                                            output_hidden_states=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "6548c3b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = TrainingArguments(\n",
    "    output_dir=\"output\",\n",
    "    evaluation_strategy=\"steps\",\n",
    "    eval_steps=conf.eval_steps,\n",
    "    per_device_train_batch_size=conf.batch_size,\n",
    "    per_device_eval_batch_size=conf.batch_size,\n",
    "    num_train_epochs=conf.epochs,\n",
    "    seed=42,\n",
    "    logging_steps=conf.logging_steps,\n",
    "    # learning_rate=conf.lr,\n",
    "    learning_rate=5e-7,\n",
    "    load_best_model_at_end=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "12a112c8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataset=train_set,\n",
    "    eval_dataset=val_set,\n",
    "    # compute_metrics=compute_metrics,\n",
    "    compute_metrics=custom_f1,\n",
    "    callbacks=[EarlyStoppingCallback(early_stopping_patience=3)],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "4aff4ff6-0fab-4dc4-a09d-d8f6ecb7d42c",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# help(Trainer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0fdb569",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Train loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "1c723afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# API key for wandb: 1fef7fd74ee7f9dfeb33b86d13b60f8ffe9c968a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "63145e4b",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='39' max='595' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 39/595 00:37 < 09:30, 0.97 it/s, Epoch 0.32/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1 for class 0</th>\n",
       "      <th>F1 for class 1</th>\n",
       "      <th>F1 for class 2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.982900</td>\n",
       "      <td>0.898993</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.836553</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.944300</td>\n",
       "      <td>0.896971</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.836553</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.906200</td>\n",
       "      <td>0.894953</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.836553</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[55], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/disk/lazarev/miniconda3/envs/study/lib/python3.10/site-packages/transformers/trainer.py:1662\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1657\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_wrapped \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\n\u001b[1;32m   1659\u001b[0m inner_training_loop \u001b[38;5;241m=\u001b[39m find_executable_batch_size(\n\u001b[1;32m   1660\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inner_training_loop, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_train_batch_size, args\u001b[38;5;241m.\u001b[39mauto_find_batch_size\n\u001b[1;32m   1661\u001b[0m )\n\u001b[0;32m-> 1662\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1663\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1664\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1665\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1666\u001b[0m \u001b[43m    \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1667\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/disk/lazarev/miniconda3/envs/study/lib/python3.10/site-packages/transformers/trainer.py:1934\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   1928\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1929\u001b[0m     tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining_step(model, inputs)\n\u001b[1;32m   1931\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   1932\u001b[0m     args\u001b[38;5;241m.\u001b[39mlogging_nan_inf_filter\n\u001b[1;32m   1933\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_tpu_available()\n\u001b[0;32m-> 1934\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (torch\u001b[38;5;241m.\u001b[39misnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43misinf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtr_loss_step\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   1935\u001b[0m ):\n\u001b[1;32m   1936\u001b[0m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[1;32m   1937\u001b[0m     tr_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m tr_loss \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_globalstep_last_logged)\n\u001b[1;32m   1938\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "580c3d47",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Custom Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d386d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "from trainer import CustomTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baea90ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = Preprocessing()\n",
    "\n",
    "result = preprocessor.get_dataloaders()\n",
    "\n",
    "train_dl = result[\"train_dl\"]\n",
    "val_dl = result[\"val_dl\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "062e079e",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = CustomTrainer(model.cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33551556-0f24-4689-b193-00938becd918",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = CustomTrainer(model.cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fea2a607",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train(train_dl, val_dl)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc8b419b-918f-4a63-ae24-789ca309bca2",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1dcc5bed-e5a7-4830-a5c7-7bc04d87002a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.8, 0. , 0. ])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score, classification_report\n",
    "y_true = [0, 1, 2, 0, 1, 2]\n",
    "y_pred = [0, 2, 1, 0, 0, 1]\n",
    "\n",
    "f1_score(y_true, y_pred, average=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "be828337-21ba-4ca8-9a52-46cc95a8a540",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      1.00      0.80         2\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.33         6\n",
      "   macro avg       0.22      0.33      0.27         6\n",
      "weighted avg       0.22      0.33      0.27         6\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "63ec837a-a27a-44b4-a3c5-dbe545a44e72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0 1 2 0 1 2'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\" \".join(map(str, y_true))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0662733c-6689-4cec-a72f-180f2cea4fd2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
